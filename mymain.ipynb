{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glmnet import LogitNet\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import load_svmlight_files\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "import csv\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computer system spec\n",
    "MacBook Air (13-inch, Early 2014)\n",
    "\n",
    "Processor 1.4 GHz Intel Core i5\n",
    "\n",
    "Memory 4 GB 1600 MHz DDR3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset Ames_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>MS_SubClass</th>\n",
       "      <th>MS_Zoning</th>\n",
       "      <th>Lot_Frontage</th>\n",
       "      <th>Lot_Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot_Shape</th>\n",
       "      <th>Land_Contour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc_Feature</th>\n",
       "      <th>Misc_Val</th>\n",
       "      <th>Mo_Sold</th>\n",
       "      <th>Year_Sold</th>\n",
       "      <th>Sale_Type</th>\n",
       "      <th>Sale_Condition</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Sale_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>526301100</td>\n",
       "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>141</td>\n",
       "      <td>31770</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Slightly_Irregular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>No_Fence</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>-93.619754</td>\n",
       "      <td>42.054035</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>526350040</td>\n",
       "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
       "      <td>Residential_High_Density</td>\n",
       "      <td>80</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>Minimum_Privacy</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>-93.619756</td>\n",
       "      <td>42.053014</td>\n",
       "      <td>105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>526351010</td>\n",
       "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>81</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Slightly_Irregular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>No_Fence</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>-93.619387</td>\n",
       "      <td>42.052659</td>\n",
       "      <td>172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>526353030</td>\n",
       "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>93</td>\n",
       "      <td>11160</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>No_Fence</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>-93.617320</td>\n",
       "      <td>42.051245</td>\n",
       "      <td>244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>527105010</td>\n",
       "      <td>Two_Story_1946_and_Newer</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>74</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Slightly_Irregular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>Minimum_Privacy</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>-93.638933</td>\n",
       "      <td>42.060899</td>\n",
       "      <td>189900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PID                          MS_SubClass                 MS_Zoning  \\\n",
       "0  526301100  One_Story_1946_and_Newer_All_Styles   Residential_Low_Density   \n",
       "1  526350040  One_Story_1946_and_Newer_All_Styles  Residential_High_Density   \n",
       "2  526351010  One_Story_1946_and_Newer_All_Styles   Residential_Low_Density   \n",
       "3  526353030  One_Story_1946_and_Newer_All_Styles   Residential_Low_Density   \n",
       "4  527105010             Two_Story_1946_and_Newer   Residential_Low_Density   \n",
       "\n",
       "   Lot_Frontage  Lot_Area Street            Alley           Lot_Shape  \\\n",
       "0           141     31770   Pave  No_Alley_Access  Slightly_Irregular   \n",
       "1            80     11622   Pave  No_Alley_Access             Regular   \n",
       "2            81     14267   Pave  No_Alley_Access  Slightly_Irregular   \n",
       "3            93     11160   Pave  No_Alley_Access             Regular   \n",
       "4            74     13830   Pave  No_Alley_Access  Slightly_Irregular   \n",
       "\n",
       "  Land_Contour Utilities     ...                Fence Misc_Feature Misc_Val  \\\n",
       "0          Lvl    AllPub     ...             No_Fence         None        0   \n",
       "1          Lvl    AllPub     ...      Minimum_Privacy         None        0   \n",
       "2          Lvl    AllPub     ...             No_Fence         Gar2    12500   \n",
       "3          Lvl    AllPub     ...             No_Fence         None        0   \n",
       "4          Lvl    AllPub     ...      Minimum_Privacy         None        0   \n",
       "\n",
       "  Mo_Sold Year_Sold Sale_Type Sale_Condition  Longitude   Latitude  Sale_Price  \n",
       "0       5      2010       WD          Normal -93.619754  42.054035      215000  \n",
       "1       6      2010       WD          Normal -93.619756  42.053014      105000  \n",
       "2       6      2010       WD          Normal -93.619387  42.052659      172000  \n",
       "3       4      2010       WD          Normal -93.617320  42.051245      244000  \n",
       "4       3      2010       WD          Normal -93.638933  42.060899      189900  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv file\n",
    "df = pd.read_csv('/Users/glen/Desktop/Statistical learning/Project/Ames_data.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>Lot_Frontage</th>\n",
       "      <th>Lot_Area</th>\n",
       "      <th>Year_Built</th>\n",
       "      <th>Year_Remod_Add</th>\n",
       "      <th>Mas_Vnr_Area</th>\n",
       "      <th>BsmtFin_SF_1</th>\n",
       "      <th>BsmtFin_SF_2</th>\n",
       "      <th>Bsmt_Unf_SF</th>\n",
       "      <th>Total_Bsmt_SF</th>\n",
       "      <th>...</th>\n",
       "      <th>Enclosed_Porch</th>\n",
       "      <th>Three_season_porch</th>\n",
       "      <th>Screen_Porch</th>\n",
       "      <th>Pool_Area</th>\n",
       "      <th>Misc_Val</th>\n",
       "      <th>Mo_Sold</th>\n",
       "      <th>Year_Sold</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Sale_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.930000e+03</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.144645e+08</td>\n",
       "      <td>57.647782</td>\n",
       "      <td>10147.921843</td>\n",
       "      <td>1971.356314</td>\n",
       "      <td>1984.266553</td>\n",
       "      <td>101.096928</td>\n",
       "      <td>4.177474</td>\n",
       "      <td>49.705461</td>\n",
       "      <td>559.071672</td>\n",
       "      <td>1051.255631</td>\n",
       "      <td>...</td>\n",
       "      <td>23.011604</td>\n",
       "      <td>2.592491</td>\n",
       "      <td>16.002048</td>\n",
       "      <td>2.243345</td>\n",
       "      <td>50.635154</td>\n",
       "      <td>6.216041</td>\n",
       "      <td>2007.790444</td>\n",
       "      <td>-93.642897</td>\n",
       "      <td>42.034482</td>\n",
       "      <td>180796.060068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.887308e+08</td>\n",
       "      <td>33.499441</td>\n",
       "      <td>7880.017759</td>\n",
       "      <td>30.245361</td>\n",
       "      <td>20.860286</td>\n",
       "      <td>178.634545</td>\n",
       "      <td>2.233372</td>\n",
       "      <td>169.142089</td>\n",
       "      <td>439.540571</td>\n",
       "      <td>440.968018</td>\n",
       "      <td>...</td>\n",
       "      <td>64.139059</td>\n",
       "      <td>25.141331</td>\n",
       "      <td>56.087370</td>\n",
       "      <td>35.597181</td>\n",
       "      <td>566.344288</td>\n",
       "      <td>2.714492</td>\n",
       "      <td>1.316613</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>0.018410</td>\n",
       "      <td>79886.692357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.263011e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>-93.693153</td>\n",
       "      <td>41.986498</td>\n",
       "      <td>12789.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.284770e+08</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>7440.250000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1965.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>793.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>-93.660217</td>\n",
       "      <td>42.022088</td>\n",
       "      <td>129500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.354536e+08</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>9436.500000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>465.500000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>-93.641806</td>\n",
       "      <td>42.034662</td>\n",
       "      <td>160000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.071811e+08</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>11555.250000</td>\n",
       "      <td>2001.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>162.750000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>801.750000</td>\n",
       "      <td>1301.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>-93.622113</td>\n",
       "      <td>42.049853</td>\n",
       "      <td>213500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.007100e+09</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1526.000000</td>\n",
       "      <td>2336.000000</td>\n",
       "      <td>6110.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>-93.577427</td>\n",
       "      <td>42.063388</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                PID  Lot_Frontage       Lot_Area   Year_Built  Year_Remod_Add  \\\n",
       "count  2.930000e+03   2930.000000    2930.000000  2930.000000     2930.000000   \n",
       "mean   7.144645e+08     57.647782   10147.921843  1971.356314     1984.266553   \n",
       "std    1.887308e+08     33.499441    7880.017759    30.245361       20.860286   \n",
       "min    5.263011e+08      0.000000    1300.000000  1872.000000     1950.000000   \n",
       "25%    5.284770e+08     43.000000    7440.250000  1954.000000     1965.000000   \n",
       "50%    5.354536e+08     63.000000    9436.500000  1973.000000     1993.000000   \n",
       "75%    9.071811e+08     78.000000   11555.250000  2001.000000     2004.000000   \n",
       "max    1.007100e+09    313.000000  215245.000000  2010.000000     2010.000000   \n",
       "\n",
       "       Mas_Vnr_Area  BsmtFin_SF_1  BsmtFin_SF_2  Bsmt_Unf_SF  Total_Bsmt_SF  \\\n",
       "count   2930.000000   2930.000000   2930.000000  2930.000000    2930.000000   \n",
       "mean     101.096928      4.177474     49.705461   559.071672    1051.255631   \n",
       "std      178.634545      2.233372    169.142089   439.540571     440.968018   \n",
       "min        0.000000      0.000000      0.000000     0.000000       0.000000   \n",
       "25%        0.000000      3.000000      0.000000   219.000000     793.000000   \n",
       "50%        0.000000      3.000000      0.000000   465.500000     990.000000   \n",
       "75%      162.750000      7.000000      0.000000   801.750000    1301.500000   \n",
       "max     1600.000000      7.000000   1526.000000  2336.000000    6110.000000   \n",
       "\n",
       "           ...        Enclosed_Porch  Three_season_porch  Screen_Porch  \\\n",
       "count      ...           2930.000000         2930.000000   2930.000000   \n",
       "mean       ...             23.011604            2.592491     16.002048   \n",
       "std        ...             64.139059           25.141331     56.087370   \n",
       "min        ...              0.000000            0.000000      0.000000   \n",
       "25%        ...              0.000000            0.000000      0.000000   \n",
       "50%        ...              0.000000            0.000000      0.000000   \n",
       "75%        ...              0.000000            0.000000      0.000000   \n",
       "max        ...           1012.000000          508.000000    576.000000   \n",
       "\n",
       "         Pool_Area      Misc_Val      Mo_Sold    Year_Sold    Longitude  \\\n",
       "count  2930.000000   2930.000000  2930.000000  2930.000000  2930.000000   \n",
       "mean      2.243345     50.635154     6.216041  2007.790444   -93.642897   \n",
       "std      35.597181    566.344288     2.714492     1.316613     0.025700   \n",
       "min       0.000000      0.000000     1.000000  2006.000000   -93.693153   \n",
       "25%       0.000000      0.000000     4.000000  2007.000000   -93.660217   \n",
       "50%       0.000000      0.000000     6.000000  2008.000000   -93.641806   \n",
       "75%       0.000000      0.000000     8.000000  2009.000000   -93.622113   \n",
       "max     800.000000  17000.000000    12.000000  2010.000000   -93.577427   \n",
       "\n",
       "          Latitude     Sale_Price  \n",
       "count  2930.000000    2930.000000  \n",
       "mean     42.034482  180796.060068  \n",
       "std       0.018410   79886.692357  \n",
       "min      41.986498   12789.000000  \n",
       "25%      42.022088  129500.000000  \n",
       "50%      42.034662  160000.000000  \n",
       "75%      42.049853  213500.000000  \n",
       "max      42.063388  755000.000000  \n",
       "\n",
       "[8 rows x 37 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descriptive statistics for each column\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2930, 83)\n",
      "Test number: 879\n",
      "unique PID number 2930\n"
     ]
    }
   ],
   "source": [
    "# df shape\n",
    "testnum = int(round(df.shape[0]*0.3 , 0))\n",
    "print(df.shape)\n",
    "print(\"Test number:\", testnum)\n",
    "\n",
    "#make sure PID is unique\n",
    "print(\"unique PID number\",pd.unique(df['PID']).size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into 70% training and 30% testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset contains 2051 rows and 82 columns\n",
      "Test dataset contains 879 rows and 82 columns\n"
     ]
    }
   ],
   "source": [
    "# Split data in input and output\n",
    "original_y = df['Sale_Price']\n",
    "original_X = df.drop(columns = ['Sale_Price'])\n",
    "\n",
    "#Split data in train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(original_X, original_y, test_size=0.3,random_state=12)\n",
    "\n",
    "print(\"Train dataset contains {0} rows and {1} columns\".format(X_train.shape[0], X_train.shape[1]))\n",
    "print(\"Test dataset contains {0} rows and {1} columns\".format(X_test.shape[0], X_test.shape[1]))\n",
    "\n",
    "#Save the train.csv and test.csv file\n",
    "\n",
    "X_train.to_csv('train.csv', index = False)\n",
    "X_test.join(y_test).to_csv('test.csv', index = False)\n",
    "\n",
    "# pd.merge(X_test,y_test,left_on='index',right_on='index')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "Because I try to use one-hot encoding later. In order to decrease the number of categories. First I delete the column if its categories exceed 15. Training dataset and test dataset would get different number of columns while doing one-hot encoding, so I need to align the X_train and X_test together to get the same number of column. Then I use imputer to replace the Nan value by the mean value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset contains 2051 rows and 74 columns\n",
      "Test dataset contains 879 rows and 74 columns\n"
     ]
    }
   ],
   "source": [
    "#data preprocessing\n",
    "\n",
    "#delete column 'Street', 'Longtitude', 'Latitude'\n",
    "X_train = X_train.drop(columns = ['Street','Longitude','Latitude','Garage_Yr_Blt'])\n",
    "X_test = X_test.drop(columns = ['Street','Longitude','Latitude','Garage_Yr_Blt'])\n",
    "\n",
    "#Choose column\n",
    "choose_column = [col for col in X_train.columns if (X_train[col].nunique() < 15 and X_train[col].dtype == \"object\") or X_train[col].dtype in ['int64','float64']]\n",
    "\n",
    "X_train = X_train[choose_column]\n",
    "X_test = X_test[choose_column]\n",
    "\n",
    "print(\"Train dataset contains {0} rows and {1} columns\".format(X_train.shape[0], X_train.shape[1]))\n",
    "print(\"Test dataset contains {0} rows and {1} columns\".format(X_test.shape[0], X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset after one hot contains 2051 rows and 264 columns\n",
      "Test dataset after one hot contains 879 rows and 256 columns\n"
     ]
    }
   ],
   "source": [
    "#implement one hot encoding to get the result\n",
    "X_train = pd.get_dummies(X_train)\n",
    "X_test = pd.get_dummies(X_test)\n",
    "print(\"Train dataset after one hot contains {0} rows and {1} columns\".format(X_train.shape[0], X_train.shape[1]))\n",
    "print(\"Test dataset after one hot contains {0} rows and {1} columns\".format(X_test.shape[0], X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset contains 2051 rows and 264 columns\n",
      "Test dataset contains 879 rows and 264 columns\n"
     ]
    }
   ],
   "source": [
    "# align X_train and X_test so column number of X_train and X_test could be the same\n",
    "\n",
    "X_train, X_test = X_train.align(X_test, join = 'left', axis=1)\n",
    "print(\"Train dataset contains {0} rows and {1} columns\".format(X_train.shape[0], X_train.shape[1]))\n",
    "print(\"Test dataset contains {0} rows and {1} columns\".format(X_test.shape[0], X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoder \n",
    "I've tried to use label encoder first, but it turns out a bad predicted result compared to one hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Label Encoder \n",
    "\n",
    "# def label_encoder(dataframe ,col_name):\n",
    "#     #Use label encoder \n",
    "#     le = preprocessing.LabelEncoder()\n",
    "#     le.fit(dataframe[col_name])\n",
    "\n",
    "#     #create a new dataframe d then replace the original value\n",
    "#     test = le.transform(dataframe[col_name]) \n",
    "#     d = {'col1': list(test)}\n",
    "#     df = pd.DataFrame(data=d, dtype=np.int8)\n",
    "    \n",
    "#     #Replace original value by label_encoded value\n",
    "#     dataframe[col_name]  = df.values\n",
    "#     return None\n",
    "\n",
    "# # X_train label_encoder transform\n",
    "# for col in X_train.columns:\n",
    "#     if X_train[col].dtype == \"object\":\n",
    "#         label_encoder(X_train,col)\n",
    "\n",
    "# # X_test label_encoder transform\n",
    "# for col in X_test.columns:\n",
    "#     if X_test[col].dtype == \"object\":\n",
    "#         label_encoder(X_test,col)\n",
    "\n",
    "# print(\"Train dataset contains {0} rows and {1} columns\".format(X_train.shape[0], X_train.shape[1]))\n",
    "# print(\"Test dataset contains {0} rows and {1} columns\".format(X_test.shape[0], X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset contains 2051 rows and 264 columns\n",
      "Test dataset contains 879 rows and 264 columns\n"
     ]
    }
   ],
   "source": [
    "#Use Imputer to deal with missing value or nan\n",
    "#train_X and test_X are numpy array\n",
    "my_imputer = Imputer(missing_values='NaN', strategy='mean')\n",
    "train_X = my_imputer.fit_transform(X_train)\n",
    "test_X = my_imputer.transform(X_test)\n",
    "print(\"Train dataset contains {0} rows and {1} columns\".format(train_X.shape[0], train_X.shape[1]))\n",
    "print(\"Test dataset contains {0} rows and {1} columns\".format(test_X.shape[0], test_X.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save X_train and y_train in csv files. Then I use glmnet in R to predict the best lambda.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save X_train & X_test as csv file which are used to compute best lambda\n",
    "# best lambda = 763.7335\n",
    "X_train.fillna(0)\n",
    "X_train.to_csv('X_train.csv', index = False)\n",
    "y_train.to_csv('y_train.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost\n",
    "XGBoost is an optimized distributed gradient boosting system designed to be highly efficient, flexible and portable. It implements machine learning algorithms under the Gradient Boosting framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-Mean-Squared-Error (RMSE) for XGBoost model is 0.1288\n"
     ]
    }
   ],
   "source": [
    "#XGboost\n",
    "XGB = XGBRegressor()\n",
    "XGB.fit(train_X, y_train, verbose=False)\n",
    "pre_test_y = XGB.predict(test_X)\n",
    "ans = round(math.sqrt(np.mean(np.square(np.log(pre_test_y) - np.log(np.array(y_test))))), 4)\n",
    "print(\"Root-Mean-Squared-Error (RMSE) for XGBoost model is {0}\".format(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the result as mysubmission1.txt\n",
    "PID = np.array(X_test['PID'].values).reshape(len(X_test),1)\n",
    "Sale_Price = pre_test_y.reshape(len(pre_test_y),1)\n",
    "ans = np.concatenate((PID,Sale_Price),axis=1)\n",
    "\n",
    "# save the data with mixted datatype, %d saves PID as integer and %10.5f can save the sale_price as double \n",
    "np.savetxt(\"mysubmission1\", ans, delimiter=',', header=\"PID,Sale_Price\", fmt='%d %10.5f', comments='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Regression\n",
    "I've tried random forest algorithm in the beginning, but the RMSE was still high. So I use GBR which is similiar to XGboost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Gradient Boosted Regression Trees\n",
    "gbrt=GradientBoostingRegressor(n_estimators=100) \n",
    "gbrt.fit(train_X, y_train) \n",
    "pre_test_y=gbrt.predict(test_X)\n",
    "ans = round(math.sqrt(np.mean(np.square(np.log(pre_test_y) - np.log(np.array(y_test))))), 4)\n",
    "print(\"Root-Mean-Squared-Error (RMSE) for GBRT model is {0}\".format(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the result as mysubmission2.txt \n",
    "PID = np.array(X_test['PID'].values).reshape(len(X_test),1)\n",
    "Sale_Price = pre_test_y.reshape(len(pre_test_y),1)\n",
    "ans = np.concatenate((PID,Sale_Price),axis=1)\n",
    "\n",
    "# save the data with mixted datatype, %d saves PID as integer and %10.5f can save the sale_price as double \n",
    "np.savetxt(\"mysubmission2\", ans, delimiter=',', header=\"PID,Sale_Price\", fmt='%d %10.5f', comments='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinate Descent lasso algorithm\n",
    "Use coordinate descent to calculate the result. Unfortunately, I can't get a decent result from this model. My smallest RMSE value is 0.48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement Lasso using Coordinate Descent\n",
    "def one_step_lasso(r, x, lam):\n",
    "    # x: nx1 matrix\n",
    "    # r: nx1 matrix\n",
    "    # Use the soft-thresholding result lasso_j = sgn(βLS_j)(|βLSj|−γ)+\n",
    "    # return beta_j\n",
    "    xx = np.sum(np.square(x))\n",
    "    xr = np.sum(x*r)\n",
    "    b = (abs(xr) -lam/2)/xx\n",
    "    b = np.sign(xr)*(b if b>0 else 0) \n",
    "    return b\n",
    "\n",
    "def mylasso(X, y, lam, n_iter, standardize = True):\n",
    "    # X: n-by-p design matrix without the intercept\n",
    "    # y: n-by-1 response vector\n",
    "    # p: p-by-1 vector\n",
    "    # lam: lambda value\n",
    "    # n.iter: number of iterations\n",
    "    # standardize: if True, center and scale X and y. \n",
    "    \n",
    "    #p is the number of features (columns)\n",
    "    p = X.shape[1]\n",
    "    \n",
    "    # n is the number of rows\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    # YOUR CODE\n",
    "    # If standardize  = TRUE, center and scale X and Y record the corresponding means and sd\n",
    "    # scaler = StandardScaler()\n",
    "    # X = scaler.fit_transform(X)\n",
    "    # y = scaler.fit_transform(y)\n",
    "    if standardize == True:\n",
    "        mean_y = np.mean(y)\n",
    "        mean_X = np.mean(X,axis = 0)\n",
    "        sd_y = np.std(y)\n",
    "        sd_X = np.std(X,axis = 0)\n",
    "        X = (X - np.mean(X,axis = 0))/np.std(X,axis = 0)\n",
    "        y = (y - np.mean(y))/np.std(y)\n",
    "\n",
    "\n",
    "    # Initial values for residual and coefficient vector b\n",
    "    # b: p-by-1 vector, without intercept\n",
    "        \n",
    "    b = np.zeros(p)\n",
    "    r = y\n",
    "\n",
    "    \n",
    "    for step in range(n_iter):\n",
    "        for j in range(p):\n",
    "        # YOUR CODE \n",
    "        # 1) Update the residual vector to be the one\n",
    "        # in blue on p37 of [lec_W3_VariableSelection.pdf]. \n",
    "        # r <-- current residual + X[, j] * b[j]\n",
    "        # r is n-by-1 vector\n",
    "\n",
    "            r = r + X[:,j]*b[j]\n",
    "        # 2) Apply one_step_lasso to update beta_j\n",
    "        # b[j] = one_step_lasso(r, X[, j], lam)\n",
    "            b[j] = one_step_lasso(r, X[:,j], lam)\n",
    "\n",
    "#         # 3) Update the current residual vector\n",
    "#         # r <-- r - X[, j] * b[j]\n",
    "            r = r - X[:,j]*b[j]\n",
    "    # YOUR CODE: scale back b and add intercept b0\n",
    "    # For b0, check p13 of [lec_W3_VariableSelection.pdf]. \n",
    "\n",
    "    b = (sd_y/sd_X)*b\n",
    "    b_intercept = mean_y - np.dot(mean_X.T,b)\n",
    "    return (b_intercept,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 1000\n",
    "X = train_X\n",
    "y = y_train\n",
    "n_iter = 50\n",
    "standardize = True\n",
    "b_intercept = mylasso(X, y, lam, n_iter)[0]\n",
    "b = mylasso(X, y, lam, n_iter)[1].reshape(264,1)\n",
    "# np.unique(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-Mean-Squared-Error (RMSE) for Coordinate decent lasso model is 0.4684\n"
     ]
    }
   ],
   "source": [
    "pre_test_y = np.dot(test_X,b) + b_intercept\n",
    "ans = round(math.sqrt(np.mean(np.square(np.log(pre_test_y) - np.array(np.log(y_test))))), 4)\n",
    "print(\"Root-Mean-Squared-Error (RMSE) for Coordinate decent lasso model is {0}\".format(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the result as mysubmission3.txt\n",
    "PID = np.array(X_test['PID'].values).reshape(len(X_test),1)\n",
    "Sale_Price = pre_test_y.reshape(len(pre_test_y),1)\n",
    "ans = np.concatenate((PID,Sale_Price),axis=1)\n",
    "\n",
    "# save the data with mixted datatype, %d saves PID as integer and %10.5f can save the sale_price as double \n",
    "np.savetxt(\"mysubmission3\", ans, delimiter=',', header=\"PID,Sale_Price\", fmt='%d %10.5f', comments='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
